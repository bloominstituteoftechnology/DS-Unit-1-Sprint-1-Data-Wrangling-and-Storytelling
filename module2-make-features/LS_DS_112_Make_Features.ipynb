{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_112_Make_Features.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fknoKxGz_jk"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 1, Sprint 1, Module 2*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qacqiXogluN_"
      },
      "source": [
        "# Learning Objectives\n",
        "\n",
        "- Objective 01 - understand the purpose of feature engineering\n",
        "- Objective 02 - demonstrate how to work with strings in pandas\n",
        "- Objective 03 - modify or create dataframe columns using the `apply()` function\n",
        "- Objective 04 - work with dates and times in pandas\n",
        "\n",
        "\n",
        "Helpful Links:\n",
        "- [Minimally Sufficient Pandas](https://medium.com/dunder-data/minimally-sufficient-pandas-a8e67f2a2428)\n",
        "- [Feature Engineering](https://en.wikipedia.org/wiki/Feature_engineering)\n",
        "- Python Data Science Handbook\n",
        "  - [Chapter 3.10](https://jakevdp.github.io/PythonDataScienceHandbook/03.10-working-with-strings.html), Vectorized String Operations\n",
        "  - [Chapter 3.11](https://jakevdp.github.io/PythonDataScienceHandbook/03.11-working-with-time-series.html), Working with Time Series\n",
        "- [Lambda Learning Method for DS - By Ryan Herr](https://docs.google.com/document/d/1ubOw9B3Hfip27hF2ZFnW3a3z9xAgrUDRReOEo-FHCVs/edit?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZSXUzBm3yvk"
      },
      "source": [
        "# [Objective 01](#feature-engineering) - The Purpose of Feature Engineering\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGHzNUcT30ui"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Feature Engineering is the process of using a combination of domain knowledge, creativity, and the pre-existing columns of a dataset to create completely new columns.\n",
        "\n",
        " Machine Learning models try to detect patterns in the data and then associate those patterns with certain predictions. The hope is that by creating new columns on our dataset that we can expose our model to new patterns in the data so that it can make better and better predictions.\n",
        "\n",
        "This is largely a matter of understanding how to work with individual columns of a dataframe with Pandas --which is what we'll be practicing today!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6vOmj_i35ef"
      },
      "source": [
        "## Follow Along\n",
        "\n",
        "Columns of a dataframe hold each hold a specific type of data. Lets inspect some of the common datatypes found in datasets and then we'll make a new feature on a dataset using pre-existing columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua6VURnC9Cny"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Pandas Display Options:\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_Y05YBr32O-"
      },
      "source": [
        "# Lets take a look at the Ames Iowa Housing Dataset:\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/Ames%20Housing%20Data/train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QmscJ7n9OSB"
      },
      "source": [
        "### Specific Columns hold specific kinds of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8rsw3zl9S3v"
      },
      "source": [
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUfKjvvSjmNe"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znph8qpr9q29"
      },
      "source": [
        "Some columns hold integer values like the `BedroomAbvGr` which stands for \"Bedrooms Above Grade.\" This is the number of non-basement bedrooms in the home.\n",
        "\n",
        "For more information on specific column meanings view the [data dictionary](https://github.com/ryanleeallred/datasets/blob/master/Ames%20Housing%20Data/data_description.txt)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl-wfFZv-_fo"
      },
      "source": [
        "# Look at a few rows of the `BedroomAbvGr` column.\n",
        "# Looks like integers to me!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHJxYRxokBjQ"
      },
      "source": [
        "What type of variable is BedroomAbvGr?  Is it categorical or quantitative?  If you answered \"categorical\", is it ordinal, nominal or an identifier?  If you answered \"quantitative\", is it continuous or discrete?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7pSVcS1kdT_"
      },
      "source": [
        "It is quantitative and discrete."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyfxM5tc_Q1w"
      },
      "source": [
        "Some columns hold float values like the `LotFrontage` column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdILA65r_PeY"
      },
      "source": [
        "# Look at a few rows of the `LotFrontage` column.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfvyHa9IfGi9"
      },
      "source": [
        "Hmmm, do the values above look like floats to you?\n",
        "\n",
        "They all have .0 on them so technically they're being stored as floats, but *should* they be stored as floats?\n",
        "\n",
        "Lets see what all of the possible values for this column are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDLnz1CX_eGc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IaYU5QzAfgn"
      },
      "source": [
        "Looks to me like the `LotFrontage` column originally held integer values but was cast to a `float` meaning that each original integer values was converted to its corresponding float representation. \n",
        "\n",
        "Any guesses as to why that would have happened?\n",
        "\n",
        "\n",
        "HINT: What's the most common `LotFrontage` value for this column?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtkV149OA5je"
      },
      "source": [
        "# NaN is the most common value in this column. What is a NaN\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJNKPLl_BQh7"
      },
      "source": [
        "`NaN` stands stands for \"Not a Number\" and is the default missing value indicator with Pandas. This means there were cells in this column that didn't have a LotFrontage value recorded for those homes. \n",
        "\n",
        "This is where domain knowledge starts to come in. Think about the context we're working with here: houses. What might a null or blank cell representing \"Linear feet of street connected to property\" mean in the context of a housing dataset?\n",
        "\n",
        "Ok, so maybe it makes sense to have some NaNs in this column. What is the datatype of a NaN value?\n",
        "\n",
        "Perhaps some of this data is truly missing or unrecorded data, but sometimes `NaNs` are more likely to indicate something that was \"NA\" or \"Not Applicable\" to a particular observation. There could be multiple reasons why there was no value recorded for a particular feature.\n",
        "\n",
        "Remember - Pandas tries to maintain a single datatype for all values in a column, and therefore..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2166y9kXB0zZ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# What is the datatype of NaN?\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37ZaBu5OB63d"
      },
      "source": [
        "The datatype of a NaN is float!  This means that if we have a column of integer values, but the column has even a single `NaN` that column will not be treated with the integer datatype but all of the integers will be converted to floats in order to try and preserve the same datatype throughout the entire column.\n",
        "\n",
        "You can see already how understanding column datatypes is crucial to understanding how Pandas help us manage our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko_yfcFqg0pj"
      },
      "source": [
        "### Making new Features\n",
        "\n",
        "Lets slim down the dataset and consider just a few specific columns:\n",
        "\n",
        "- `TotalBsmtSF`\n",
        "- `1stFlrSF`\n",
        "- `2ndFlrSF`\n",
        "- `SalePrice1`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GxPTgevhWnv"
      },
      "source": [
        "# I can make a smaller dataframe with a few specific column headers\n",
        "# by passing a list of column headers inside of the square brackets\n",
        "# get a single column\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auAhDXBpAKmz"
      },
      "source": [
        "# Get more than one column, then pass in a list of column headers\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZQiF1gUAQAp"
      },
      "source": [
        "# I can make a smaller dataframe with a few specific column headers\n",
        "# by passing a list of column headers inside of the square brackets\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL6ATJdNAbsY"
      },
      "source": [
        "small_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw0PzxkbiQmm"
      },
      "source": [
        "### Syntax for creating new columns\n",
        "\n",
        "When making a new column on a dataframe, we have to use the square bracket syntax of accessing a column. We can't use \"dot syntax\" here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkXHP57_iJ-U"
      },
      "source": [
        "# Lets add up all of the square footage to get a single square footage \n",
        "# column for the entire dataset\n",
        "\n",
        "# Using bracket syntax to make a new 'TotalSquareFootage' column\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEy-6VQCi08c"
      },
      "source": [
        "# Lets make a nother new column that is 'PricePerSqFt' by\n",
        "# dividing the price by the square footage\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvkB9z0ohQG6"
      },
      "source": [
        "###We can also use if-then statements to create new variables.  \n",
        "\n",
        "Say we want to categorize houses as having a high price per square foot (greater than or equal to 80 dollars per square foot) or a low price per square foot (less than 80 dollars per square foot)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "649cPb-chjRf"
      },
      "source": [
        "\n",
        "#pd.crosstab(small_df['High_ppsqft'],columns='count')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ-GGFwKkPjF"
      },
      "source": [
        "Now we have added several new columns on our small dataset.\n",
        "\n",
        "- What does a **high** `PricePerSqFt` say about a home that the square footage and price alone don't capture as directly?\n",
        "\n",
        "- What does a **low** `PricePerSqFt` say about a home that the square footage and price alone don't directly capture?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cav0rJH2qV4I"
      },
      "source": [
        "### Let's include \"and\" and \"or\" conditions in the if-then statements.\n",
        "\n",
        "Let's identify the 2-story duplex houses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtcTlkd-q2EX"
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA7zR5r6wgq_"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihAzxhCjs1IM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BbCu3ii4LK8"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "I hope you can see how we have used existing columns to create a new column on a dataset that say something new about our unit of observation. This is what making new features (columns) on a dataset is all about and why it's so essential to data science --particularly predictive modeling \"Machine Learning.\" \n",
        "\n",
        "We'll spend the rest of the lecture and assignment today trying to get as good as we can at manipulating (cleaning) and creating new columns on datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKnLv6nGmU8N"
      },
      "source": [
        "# [Objective 02](#work-with-strings) - Work with Strings with Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cllyKRVOmZW1"
      },
      "source": [
        "# [Objective 03](#pandas-apply) - Modify and Create Columns using `.apply()`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqd_Lpb9ntwT"
      },
      "source": [
        "## Overview\n",
        "\n",
        "So far we have worked with numeric datatypes (ints and floats) but we haven't worked with any columns containing string values. We can't simply use arithmetic to manipulate string values, so we'll need to learn some more techniques in order to work with this datatype."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6UBXPhQnxzj"
      },
      "source": [
        "## Follow Along\n",
        "\n",
        "We're going to import a new dataset here to work with. This dataset is from LendingClub and holds information about loans issued in Q4 of 2018. This dataset is a bit messy so it will give us plenty of opportunities to clean up existing columns as well as create new ones.\n",
        "\n",
        "The `!wget` shell command being used here does exactly the same thing that your browser does when you type a URL in the address. It makes a request or \"gets\" the file at that address. However, in our case the file isn't a webpage, it's a compressed CSV file. \n",
        "\n",
        "Try copying and pasting the URL from below into your browser, did it start an automatic download? Any URLs like this that start automatic downloads when navigated to can be used along with the `!wget` command to bring files directly into your notebook's memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1SkaCMTsCyT"
      },
      "source": [
        "### Load a new dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeEKWHB0n2fq"
      },
      "source": [
        "!wget https://resources.lendingclub.com/LoanStats_2018Q4.csv.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqUSbgIJqAB8"
      },
      "source": [
        "We need to use the `!unzip` command to extract the csv from the zipped folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbw0l5wyqLeI"
      },
      "source": [
        "!unzip LoanStats_2018Q4.csv.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPB0-7F_qNFT"
      },
      "source": [
        "We can also use bash/shell commands to look at the raw file using the `!head` and `!tail` commands"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcWpsAmFqTF4"
      },
      "source": [
        "!head LoanStats_2018Q4.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-uPShUxqa9O"
      },
      "source": [
        "!tail LoanStats_2018Q4.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_bEBsHTqduT"
      },
      "source": [
        "As we look at the raw file itself, do you see anything that might cause us trouble as we read in the CSV file to a dataframe?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikpjHKeiqlWp"
      },
      "source": [
        "# Read in the CSV\n",
        "\n",
        "df = pd.read_csv('LoanStats_2018Q4.csv', header=1)\n",
        "\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvqwNrQlq5fr"
      },
      "source": [
        "The extra rows at the top and bottom of the file have done two things:\n",
        "\n",
        "1) The top row has made it so that the entire dataset is being interpreted as column headers\n",
        "\n",
        "2) The bottom two rows have been read into the 'id' column and are causing every column to have at least two `NaN` values in it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKM5P0RzrLh8"
      },
      "source": [
        "# We can fix the header problem by using the 'skiprows' parameter\n",
        "\n",
        "df = pd.read_csv('LoanStats_2018Q4.csv', skiprows=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuLO7bhTrY0z"
      },
      "source": [
        "Lets look at the NaN values of each column so that you can see the problem that the extra rows at the bottom of the file are creating for us"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12OtVOd9rdb-"
      },
      "source": [
        "# Sum null values by column and sort from least to greatest\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsrL1ai9KgFS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4793LweyroFI"
      },
      "source": [
        "# Address the extra NaNs in each column by skipping the footer as well.\n",
        "df = pd.read_csv('LoanStats_2018Q4.csv', skiprows=1, skipfooter=2, engine='python')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7w8iGhyr0Bu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzPuC7jUstVF"
      },
      "source": [
        "For good measure, we'll also drop some columns that are made up completely of NaN values.\n",
        "\n",
        "Why might LendingClub have included columns in their dataset that are 100% blank?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HubXTHZ3sj6n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcmxUo8LLHsr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE3scusaLNtu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87lzDxnCr_6j"
      },
      "source": [
        "### Clean up the `int_rate` column\n",
        "\n",
        "When we're preparing a dataset for a machine learning model we typically don't want to leave any string values in our dataset --because it's hard to do math on words. \n",
        "\n",
        "Specifically, we have a column that is representing a numeric value, but currently doesn't have a numeric datatype. Lets look at the first 10 values of the `int_rate` column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQRxQs3-tnup"
      },
      "source": [
        "# Look at the first 10 values of the int_rate column\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu2lMR4wtt-M"
      },
      "source": [
        "# Look at a specific value from the int_rate column\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_jaqVUWnb-9"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umnBqFa0t22W"
      },
      "source": [
        "Problems that we need to address with this column:\n",
        "\n",
        "- String column that should be numeric\n",
        "- Percent sign `%` included with the number\n",
        "- Leading space at the beginning of the string\n",
        "\n",
        "However, we're not going to try and write exactly the right code to fix this column in one go. We're going to methodically build up to the code that will help us address these problems.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qveVttHSuVlh"
      },
      "source": [
        "# Lets start with just fixing a single string.\n",
        "# If we can fix one, we can usually fix all of them\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3bRlDUbus9m"
      },
      "source": [
        "#Remove extra white space\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfFY8nGluouN"
      },
      "source": [
        "#Doesn't work if there isn't any extra white space to remove\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA-FB2WEuvZr"
      },
      "source": [
        "#You can \"chain\" two strip functions to remove both the spaces and the % sign\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjhHPbDtuxtU"
      },
      "source": [
        "# \"Cast\" the string value to a float\n",
        "# \"cast\" -> Change something's data type\n",
        "# This is the line of code that we're after! ->\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcqneHUmvCs6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_bTzHIJvc8M"
      },
      "source": [
        "### Write a function to make our solution reusable!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAEyVD-WoXDW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYJYsfQZvVcK"
      },
      "source": [
        "# Write a function that can do what we have written above to any \n",
        "# string that is passsed to it.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng3lQFD8vxQt"
      },
      "source": [
        "# Test out our function by calling it on our example\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cPxk1W9v2ul"
      },
      "source": [
        "# is the data type correct?\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgxdjRqnv-ZH"
      },
      "source": [
        "### Apply our solution to every cell in a column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGJmf1IbwE1Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7wMZexFozBd"
      },
      "source": [
        "# pass in *only* the name of the function, don't call it. \n",
        "# This works because we know the function works on every item in the column\n",
        "# so I can simply \"apply\" it to the entire column\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYCez3j5wLWt"
      },
      "source": [
        "\n",
        "# What type of data is held in our new column?\n",
        "\n",
        "# Look at the datatypes of the last 5 columns\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOXkc5own3LM"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "We can create a new column with our cleaned values or overwrite the original, whatever we think best suits our needs. On your assignment you will take the same approach in trying to methodically build up the complexity of your code until you have a few lines that will work for any cell in a column. At that point you'll contain all of that functionality in a reusable function block and then use the `.apply()` function to... well... apply those changes to an entire column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0G8Kv-MmaHh"
      },
      "source": [
        "# [Objective](#dates-and-times) Work with Dates and Times with Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "565Xjo-RnvLm"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Pandas has its own datatype datatype that makes it extremely convenient to convert strings that are in standard date formates to datetime objects and then use those datetime objects to either create new features on a dataframe or work with the dataset in a timeseries fashion. \n",
        "\n",
        "This section will demonstrate how to take a column of date strings, convert it to a datetime object and then use the datetime formatting `.dt` to access specific parts of the date (year, month, day) to generate useful columns on a dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpoU_2Gknzbz"
      },
      "source": [
        "## Follow Along"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoQ86d_R79J6"
      },
      "source": [
        "### Work with Dates \n",
        "\n",
        "pandas documentation\n",
        "- [to_datetime](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_datetime.html)\n",
        "- [Time/Date Components](https://pandas.pydata.org/pandas-docs/stable/timeseries.html#time-date-components) \"You can access these properties via the `.dt` accessor\"\n",
        "\n",
        "Many of the most useful date columns in this dataset have the suffix `_d` to indicate that they correspond to dates.\n",
        "\n",
        "We'll use a list comprehension to print them out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxOhEaEX76mY"
      },
      "source": [
        "[col for col in df if col.endswith('_d')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wccaSfx9Zo4"
      },
      "source": [
        "Lets look at the string format of the `issue_d` column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVYeLIOm9dQ-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnjOcU5y9iZh"
      },
      "source": [
        "Because this string format %m-%y is a common datetime format, we can just let Pandas detect this format and translate it to the appropriate datetime object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBV3Ta_79qe6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hcypFMu9y4s"
      },
      "source": [
        "Now we can see that the `issue_d` column has been changed to hold `datetime` objects.\n",
        "\n",
        "Lets look at one of the cells specifically to see what a datetime object looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUMjhnyJ94is"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZQiLh4O-CMN"
      },
      "source": [
        "You can see how the month and year have been indicated by the strings that were contained in the column previously, and that the rest of the values have been inferred."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_PhaWzb-J7X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3rKmrzY-NsD"
      },
      "source": [
        "We can use the `.dt` accessor to now grab specific parts of the datetime object. Lets grab just the year from the all of the cells in the `issue_d` column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4479qzj-Yj5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coNYQvdJ-b0s"
      },
      "source": [
        "Now the month."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D28keYR3-dJn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4_O0q0t-hOX"
      },
      "source": [
        "It's just that easy! Now, instead of printing them out, lets add these year and month values as new columns on our dataframe. Again, you'll have to scroll all the way over to the right in the table to see the new columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJdlhqH1-mri"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAxig0nE-1kt"
      },
      "source": [
        "Because all of these dates come from Q4 of 2018, the `issue_d` column isn't all that interesting. Lets look at the `earliest_cr_line` column, which is also a string, but that could be converted to datetime format.\n",
        "\n",
        "We're going to create a new column called `days_from_earliest_credit_to_issue`\n",
        "\n",
        "It's a long column header, but think about how valuable this piece of information could be. This number will essentially indicate the length of a person's credit history and if that is correlated with repayment or other factors could be a valuable predictor!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S6BDZjp-e8-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0VwXV1F_YpZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRWE2SXZe8mA"
      },
      "source": [
        "\n",
        "\n",
        "#Don't forget leap year = 365.25 each year.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml-N769C_e_n"
      },
      "source": [
        "What we're about to do is so cool! Pandas' datetime format is so smart that we can simply use the subtraction operator `-` in order to calculate the amount of time between two dates. \n",
        "\n",
        "Think about everything that's going on under the hood in order to give us such straightforward syntax! Handling months of different lengths, leap years, etc. Pandas datetime objects are seriously powerful!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWu1a57V_cHx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHQEQZx6_3_p"
      },
      "source": [
        "What's oldest credit history that was involved in Q4 2018? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrEqk6hG_20O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gORWK62cAF2a"
      },
      "source": [
        "25,171 days is ~ 68.96 years of credit history!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THRLJ-7Jn4om"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "Pandas' datetime format is so easy to work with that there's really no excuse for not using dates to make features on a dataframe! Get ready to practice more of this on your assignment."
      ]
    }
  ]
}